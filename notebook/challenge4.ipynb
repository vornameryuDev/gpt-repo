{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# challenge4\n",
    "- ConversationBufferMemory: 이전 대화내용 그대로 저장\n",
    "- Stuff Documents chain: docs > 하나의doc > answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[stuff]\\n1. 실행구조\\n    human: Question\\n    ai: invoke(question, retriever, history(memory)) > result > save(memory)\\n\\n2. retriever산출(stuff)\\n    1) load_file\\n    2) text_split\\n    3) embeddings & cache\\n    4) vectorstore > retriever\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[stuff]\n",
    "1. 실행구조\n",
    "    human: Question\n",
    "    ai: invoke(question, retriever, history(memory)) > result > save(memory)\n",
    "\n",
    "2. retriever산출(stuff)\n",
    "    1) load_file(o)\n",
    "    2) text_split(o)\n",
    "    3) embeddings & cache(o)\n",
    "    4) vectorstore > retriever(o)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\web\\gpt-repo\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "d:\\web\\gpt-repo\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:151: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "\n",
    "#---------- function\n",
    "# retiever format\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "#load memory\n",
    "def load_memory(_):\n",
    "    print(memory.load_memory_variables({})[\"history\"])\n",
    "    print()\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "def embed_file(file):\n",
    "    #load_file    \n",
    "    loader = TextLoader(file)\n",
    "\n",
    "    #split file\n",
    "    splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=600,\n",
    "        chunk_overlap=100,\n",
    "    )\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    print(len(docs))    \n",
    "\n",
    "    #embeddings & cache\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    file_name = file.split('/')[-1]\n",
    "    cache_path = LocalFileStore(f\"./.cache/embeddings/{file_name}\") \n",
    "    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_path)\n",
    "\n",
    "    #vectorstore > retriever\n",
    "    vectorstore = Chroma.from_documents(docs, cached_embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        {'input': question},\n",
    "        {'output': result.content}\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "#--------- retriever\n",
    "file_path = r\"../files/chapter3.txt\"\n",
    "retriever = embed_file(file_path)\n",
    "\n",
    "\n",
    "#---------- prompt & invoke\n",
    "llm = ChatOpenAI(temperature=0.1) #llm\n",
    "memory = ConversationBufferMemory(return_messages=True) #memory\n",
    "#prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        'system',\n",
    "        \"\"\"\n",
    "            너는 도움을 주는 훌륭한 조수야. 주어지는 문서에서 묻는 말에 대한 답을 찾아줘. 만약 문서안에 답이 없다면 모르겠다고 대답해.\\n\\n{context}\n",
    "        \"\"\",\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"history\": load_memory\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.' response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 2435, 'total_tokens': 2460}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-858e803d-6584-4b55-8a8d-4871a2dbfa74-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Is Aaronson guilty?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.')]\n",
      "\n",
      "content='The message he wrote on the table was: \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\".' response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 2448, 'total_tokens': 2477}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-6dd1e2e1-478f-4f0a-acfe-321606a5cc8e-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('What message did he write in the table?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'), HumanMessage(content='What message did he write in the table?'), AIMessage(content='The message he wrote on the table was: \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\".')]\n",
      "\n",
      "content='Julia is a character in the text who is involved in a romantic relationship with Winston.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 2479, 'total_tokens': 2497}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-680d04b5-09cb-4ef5-a058-23f1d73620ea-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Who is Julia?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'), HumanMessage(content='What message did he write in the table?'), AIMessage(content='The message he wrote on the table was: \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\".'), HumanMessage(content='Who is Julia?'), AIMessage(content='Julia is a character in the text who is involved in a romantic relationship with Winston.')]\n",
      "\n",
      "content='죄를 지은 것으로 기록되어 있지만, 실제로는 그들이 유죄임이 밝혀진 사진을 본 적이 없다고 기억합니다.' response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 2534, 'total_tokens': 2586}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-a855d891-3d86-4783-9bef-1fc2a186a1ea-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Aaronson 은 유죄인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'), HumanMessage(content='What message did he write in the table?'), AIMessage(content='The message he wrote on the table was: \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\".'), HumanMessage(content='Who is Julia?'), AIMessage(content='Julia is a character in the text who is involved in a romantic relationship with Winston.'), HumanMessage(content='Aaronson 은 유죄인가요?'), AIMessage(content='죄를 지은 것으로 기록되어 있지만, 실제로는 그들이 유죄임이 밝혀진 사진을 본 적이 없다고 기억합니다.')]\n",
      "\n",
      "content='그가 테이블에 쓴 메시지는 \"자유는 노예다\"와 \"2와 2는 5다\" 입니다.' response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 2618, 'total_tokens': 2659}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2cfb27a6-814a-45de-9874-87cb288d7cbe-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('그가 테이블에 어떤 메시지를 썼나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content='Yes, according to the text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.'), HumanMessage(content='What message did he write in the table?'), AIMessage(content='The message he wrote on the table was: \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE\".'), HumanMessage(content='Who is Julia?'), AIMessage(content='Julia is a character in the text who is involved in a romantic relationship with Winston.'), HumanMessage(content='Aaronson 은 유죄인가요?'), AIMessage(content='죄를 지은 것으로 기록되어 있지만, 실제로는 그들이 유죄임이 밝혀진 사진을 본 적이 없다고 기억합니다.'), HumanMessage(content='그가 테이블에 어떤 메시지를 썼나요?'), AIMessage(content='그가 테이블에 쓴 메시지는 \"자유는 노예다\"와 \"2와 2는 5다\" 입니다.')]\n",
      "\n",
      "content='Julia는 텍스트 속에서 윈스턴과 로맨틱한 관계에 있는 캐릭터입니다.' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 2662, 'total_tokens': 2696}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-42db2cde-2bea-4b7b-b5cf-e416314b97d2-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Julia 는 누구인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
