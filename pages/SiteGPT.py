'''
- cloudflare sitemap
    - ì˜ˆì‹œ: https://api.python.langchain.com/sitemap.xml
    - https://developers.cloudflare.com/sitemap-0.xml
    - AIGateway
    - Cloudflare vectorize
    - Workers AI
- Questions
    - "What is the price per 1M input tokens of the llama-2-7b-chat-fp16 model?"
    - "What can I do with Cloudflareâ€™s AI Gateway?"
    - "How many indexes can a single account have in Vectorize?"
- conditions
    - Allow the user to use its own OpenAI API Key: st.sidebar, st.text_input
    - put a link to the Github repo: st.sidebar

- ê¸°ëŠ¥êµ¬í˜„ ìˆœì„œ
    - url > ë‚´ìš© ê°€ì ¸ì˜¤ê¸° = retriever
        - urlì…ë ¥
        - parsing: url ë‚´ìš© í…ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°
        - split
        - embedding & caching
        - vectorstore
    - {'context': retriever} | example_prompt | llm = chain
    - chain.invoke = result
'''



import streamlit as st



#---------- config
st.set_page_config(
    page_icon="ğŸ¤£",
    page_title="SiteGPT"
)

#---------- function
from langchain_community.document_loaders import SitemapLoader
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore
from langchain_community.vectorstores import FAISS
from langchain.callbacks import StreamingStdOutCallbackHandler
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda



def parse_page(soup):        
    return (
        str(soup.get_text()).replace('\n','').replace('\xa0', '')
    )


@st.cache_resource(show_spinner="Loading website...")
def load_website(url):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    loader = SitemapLoader(
        url,
        filter_urls=[
            r"^(.*\/ai-gateway\/).*",
            r"^(.*\/vectorize\/).*",
            r"^(.*\/workers-ai\/).*",     
        ],
        parsing_function=parse_page
    )
    st.write(loader.load())
    print('loadingì™„ë£Œ')
    loader.requests_per_second = 2
    docs = loader.load_and_split(
        text_splitter=splitter
    )
    print("ë¶„í•  ì‹œì‘")   
    vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
    print("vectorstore ì™„ë£Œ")
    return vector_store.as_retriever()  

def send_message(role, message):
    with st.chat_message(role):
        st.write(message)


def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = answers_prompt | llm
    return {
        "question": question,
        "answers": [
            {
                "answer": answers_chain.invoke(
                    {"question": question, "context": doc.page_content}
                ).content,
                "source": doc.metadata["source"],
                "date": doc.metadata["lastmod"],
            }
            for doc in docs
        ],
    }



def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    choose_chain = choose_prompt | llm
    condensed = "\n\n".join(
        f"{answer['answer']}\nSource:{answer['source']}\n"
        for answer in answers
    )
    return choose_chain.invoke(
        {
            "question": question,
            "answers": condensed,
        }
    )


#---------- sidebar
with st.sidebar:
    url = st.text_input(
        label="Write down a URL",
        placeholder="https://example.com"
    )


#---------- main
##header
st.title("SiteGPT")

##main
# map re duce 
if url:
    retriever = load_website(url=url)
    st.write('retriever ì™„ë£Œ')

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()]
    )
    answers_prompt = ChatPromptTemplate.from_messages([
        (
            'system',
            '''                
                contextì— ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì•„ë˜ì™€ ê°™ì€ ì˜ˆì‹œë¡œ ëŒ€ë‹µí•´. ì ìˆ˜ëŠ” 0ì ë¶€í„° 5ì ê¹Œì§€ ì¤„ ìˆ˜ ìˆì–´. ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ê¹Šì„ìˆ˜ë¡ ì ìˆ˜ëŠ” ë†’ì•„ì•¼ í•´. 0ì ì´ë¼ë„ í•­ìƒ ë‹µë³€ì˜ ì ìˆ˜ë¥¼ í¬í•¨í•´

                context: {context}

                Ouput Example:
                    Question: How far away is the moon?
                    Answer: The moon is 384,400 km away.
                    Score: 5
                                                                
                    Question: How far away is the sun?
                    Answer: I don't know
                    Score: 0
            '''
        ),
        ('human','{question}')
    ])

    question = "How many indexes can a single account have in Vectorize?"
    answer_chain = answers_prompt | llm
    answers = []
    for i, doc in enumerate(retriever):    
        print(i)
        print(doc)
        result = answer_chain.invoke(
            {
                'context': doc,
                'question': question
            }
        )
        answers.append(result)
        print(result)
    st.write(answers)


      
    
    
    



    


    # question = "How many indexes can a single account have in Vectorize?"
    # chain = answers_prompt | llm
    # answers = []
    # for doc in retriever:
    #     result = {
    #         'question': question,
    #         'answer': chain.invoke(
    #             {
    #                 'context': doc.page_content,
    #                 'question': question
    #             }
    #         )
    #     }
    #     answers.append(result)
    # st.write(answers)









        